{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2406332",
   "metadata": {},
   "source": [
    "# 🐦 **Kaggle BirdCLEF+2025 Competition**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **최종 결과**\n",
    "| 단계                                 | Public Score | Private Score | 제출 여부 | 최종 리더보드 순위 |\n",
    "|--------------------------------------|:------------:|:-------------:|:---------:|:----------------------:|\n",
    "| 1. 처음 5초 세그먼트 선택  |     0.793     |     0.803     |     -     |           -            |\n",
    "| 2. 조건 기반 세그먼트 선택 |     0.809     |     0.821     |     -     |           -            |\n",
    "| 3. 모델 변경 및 하이퍼파라미터 튜닝 |  0.825    |     0.841     |     -     |           -            |\n",
    "| 4. 모델 아키텍처 수정         |     0.835     |   **0.847**   |    ✓      |           -            |\n",
    "| 5. 공개 모델 앙상블             |     0.878     |   **0.893**   |     -     |           -            |\n",
    "| 6. 후처리 기법 적용       |     0.881     |   **0.891**   |    ✓      |   **507 / 2026**       |\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **대회 정보**\n",
    "- **대회명**: [BirdCLEF+2025](https://www.kaggle.com/competitions/birdclef-2025)\n",
    "- **주최**: Cornell Lab of Ornithology, LifeCLEF\n",
    "- **기간**: 2025년 3월 10일 ~ 6월 5일 (UTC 기준)\n",
    "- **참가 팀 수**: 2,026팀\n",
    "- **평가 방식**: 클래스별 Macro-average ROC-AUC (테스트셋에 존재하지 않는 클래스는 제외)\n",
    "- **제출 형식**:\n",
    "  - 5초 단위 오디오 세그먼트마다 206개 종에 대한 존재 확률 예측\n",
    "  - 코드 제출은 최대 2개까지 가능하며, 최종 순위는 Private Score 기준\n",
    "- **과제 목표**: 자연 환경에서 녹음된 60초 사운드스케이프 오디오로부터 206종의 동물을 탐지 및 분류\n",
    "- **실행 제한 조건**:\n",
    "  - 인터넷 비활성화\n",
    "  - 노트북 실행 시간 제한: CPU 기준 90분 이내 / GPU 기준 1분 이내\n",
    "  - 공개된 외부 데이터셋 및 사전학습 모델 사용 가능\n",
    "  - 출력 파일명은 반드시 `submission.csv`로 저장\n",
    "\n",
    "---\n",
    "\n",
    "### 👥 **팀 구성 및 역할**\n",
    "- **참여 기간**: 2025년 5월 2일 ~ 6월 5일 (UTC 기준)\n",
    "- **팀 구성**: 총 5인 팀으로 참가\n",
    "- **담당 역할**: 조장  \n",
    "  전처리부터 모델 설계, 실험, 앙상블에 이르기까지 전체 파이프라인을 주도적으로 설계 및 구현\n",
    "  - 세그먼트 선택 기준 및 전처리 전략 설계\n",
    "  - 모델 및 앙상블 구조 설계\n",
    "  - 후처리 및 클래스 가중치 조정 전략 주도\n",
    "  - 다양한 실험을 계획하고 End-to-End 파이프라인 직접 구현\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠️ **사용한 기술 및 라이브러리**\n",
    "- **언어**: Python 3.11\n",
    "- **딥러닝 프레임워크**: PyTorch\n",
    "- **모델 구조 및 백본**: `timm` (EfficientNet, NFNet, SE-ResNeXt)\n",
    "- **오디오 처리**: `librosa`, `torchaudio` (MelSpectrogram, AmplitudeToDB 등)\n",
    "- **데이터 처리**: `numpy`, `pandas`, `scikit-learn`\n",
    "- **시각화**: `matplotlib`, `seaborn`\n",
    "\n",
    "---\n",
    "\n",
    "### 💻 **개발 환경**\n",
    "- **운영체제**: Ubuntu 24.04\n",
    "- **개발 도구**: VSCode\n",
    "- **하드웨어**\n",
    "  - CPU: Ryzen 9 5900X\n",
    "  - RAM: 16GB × 2 = 32GB\n",
    "  - GPU: Nvidia 4070Ti (12GB VRAM)\n",
    "- **추가 환경**: Kaggle Notebooks\n",
    "  - 여러 모델을 병렬로 학습 및 추론 수행\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 📂 **데이터셋 개요**\n",
    "\n",
    "- **`train_audio`**\n",
    "  - 약 20,000개의 오디오 클립 (각 5~60초 길이)\n",
    "  - 조류(Aves), 양서류(Amphibia), 포유류(Mammalia), 곤충(Insecta)의 소리 포함\n",
    "  - Xeno-canto, iNaturalist, CSA 등에서 수집됨 (32kHz, OGG 포맷)\n",
    "  - 약한 라벨(weak label)이 부여된 데이터\n",
    "\n",
    "- **`train_soundscapes`**\n",
    "  - 라벨이 없는 60초 길이의 녹음 약 10,000개\n",
    "  - 테스트 환경과 유사한 장소에서 수집됨\n",
    "\n",
    "- **`test_soundscapes`**\n",
    "  - 평가용으로 제공된 1분 길이의 오디오 약 700개\n",
    "  - 자동으로 테스트 디렉토리에 배치됨 (32kHz, OGG 포맷)\n",
    "\n",
    "- **`train.csv`**\n",
    "  - `primary_label`, `secondary_labels`, `latitude`, `longitude`, `author`, `filename`, `rating`, `collection` 등의 메타데이터 포함\n",
    "\n",
    "- **`sample_submission.csv`**\n",
    "  - `row_id` (soundscape_id_end_time) 형식의 ID\n",
    "  - 206개 종에 대한 존재 확률 예측값을 제출하는 형식\n",
    "\n",
    "- **`taxonomy.csv`**\n",
    "  - 종 ID, 학명, 분류군 정보 포함 (조류 / 양서류 / 포유류 / 곤충)\n",
    "\n",
    "- **`recording_location.txt`**\n",
    "  - 콜롬비아 El Silencio 자연 보호구역의 녹음 위치에 대한 설명 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb82d82",
   "metadata": {},
   "source": [
    "### 📖 **베이스라인 코드 (Public 점수: 0.761)**\n",
    "\n",
    "- **전처리 베이스라인**: [멜스펙트로그램 전처리 코드 (Kadir Candisolu)](https://www.kaggle.com/code/kadircandrisolu/transforming-audio-to-mel-spec-birdclef-25)\n",
    "    - **설정 값**\n",
    "        - 샘플링 레이트: 32 kHz  \n",
    "        - 세그먼트 길이: 5초  \n",
    "        - 대상 이미지 크기: 256 × 256  \n",
    "        - 멜스펙트로그램 파라미터: `n_fft=1024`, `hop_length`, `n_mels=128`, `fmin=50`, `fmax=14000`\n",
    "    - **워크플로우**\n",
    "        1. 중앙 5초 세그먼트를 추출\n",
    "        2. 길이가 부족한 경우 반복 및 패딩\n",
    "        3. `librosa.feature.melspectrogram`을 이용해 변환 → 데시벨 스케일 → min-max 정규화 [0–1]\n",
    "        4. `cv2.resize`로 (256, 256) 크기로 리사이즈 후 `.npy` 파일로 저장\n",
    "\n",
    "- **학습 베이스라인**: [EfficientNet-B0 PyTorch 학습 코드 (Kadir Candisolu)](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-train-birdclef-25)\n",
    "    - **데이터 증강**\n",
    "        - SpecAugment (시간/주파수 마스킹)\n",
    "        - 밝기 및 대비 랜덤 조절\n",
    "        - Mixup 정규화\n",
    "    - **모델 구성**\n",
    "        - 백본: `timm.create_model('efficientnet_b0', pretrained=True, in_chans=1)`\n",
    "        - 분류기: `AdaptiveAvgPool2d → Dropout(0.2) → Linear(num_classes)`\n",
    "    - **학습 설정**\n",
    "        - 손실 함수: `BCEWithLogitsLoss`\n",
    "        - 옵티마이저: `AdamW`\n",
    "        - 학습률 스케줄러: `CosineAnnealingLR`\n",
    "        - 교차검증: `StratifiedKFold(n_splits=5)`\n",
    "\n",
    "- **추론 베이스라인**: [EfficientNet-B0 PyTorch 추론 코드 (Kadir Candisolu)](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25)\n",
    "    - **설정 값**: 학습 시와 동일한 설정 사용\n",
    "    - **추론 워크플로우**\n",
    "        1. 60초 오디오를 5초 단위로 분할 → `total_segments = 길이 / 5`\n",
    "        2. 각 세그먼트를 멜스펙트로그램으로 변환 후 256×256으로 리사이즈\n",
    "        3. 각 fold 모델로 예측하고 `sigmoid(outputs)` 적용 → **소프트 보팅**\n",
    "    - **제출**\n",
    "        - 예측 결과를 `sample_submission.csv` 형식에 맞게 채워 `submission.csv`로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51347e",
   "metadata": {},
   "source": [
    "### **1. 세그먼트 위치 조정 및 후처리 추가 (PB 0.761 → 0.793 | PV 0.803)**\n",
    "\n",
    "- **세그먼트 위치 변경**\n",
    "    - **변경 전**: 중앙 5초 세그먼트 사용 (베이스라인)\n",
    "    - **변경 후**: 오디오 파일의 첫 5초 사용\n",
    "\n",
    "- **후처리 (Temporal Smoothing)**\n",
    "    - **양 끝 세그먼트**: 이전/다음 세그먼트와 가중 평균 (0.8 / 0.2)\n",
    "    - **중간 세그먼트**: 이전/현재/다음 세그먼트 가중 평균 (0.2 / 0.6 / 0.2)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 조건 기반 세그먼트 선택 (PB 0.793 → 0.809 | PV 0.803 → 0.821)**\n",
    "\n",
    "1. **짧은 오디오 처리**\n",
    "    - 길이 < 5초인 경우: 반복 및 패딩을 통해 5초 세그먼트 생성\n",
    "\n",
    "2. **CSA 녹음 예외 처리** (기본적으로 사람 음성이 포함됨)\n",
    "    - 리스닝 테스트 결과, `CSA`로 시작하는 파일에는 일관적으로 사람 음성이 포함됨\n",
    "    - 해당 파일은 고정된 2~7초 구간만 사용 (사람 소음이 적은 구간)\n",
    "\n",
    "3. **유효 세그먼트 탐지**\n",
    "    - 기준 조건: 주파수 ≥ 2kHz, 음압 ≥ -27.5dB\n",
    "    - 1초 간격의 슬라이딩 윈도우로 5초 구간 검사\n",
    "    - 가장 유효한 프레임이 많은 구간 선택, 없으면 기본 2~7초 구간 사용\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 모델 및 하이퍼파라미터 개선 (PB 0.809 → 0.825 | PV 0.821 → 0.841)**\n",
    "\n",
    "- **백본 모델 교체**\n",
    "    - **변경 전**: `efficientnet_b0`\n",
    "    - **변경 후**: `tf_efficientnetv2_s.in21k_ft_in1k`\n",
    "\n",
    "- **멜스펙트로그램 하이퍼파라미터 변경**\n",
    "\n",
    "| 파라미터       | 변경 전 | 변경 후 |\n",
    "|----------------|:-------:|:-------:|\n",
    "| `n_fft`        | 1024    | 2048    |\n",
    "| `hop_length`   | 512     | 512     |\n",
    "| `n_mels`       | 128     | 512     |\n",
    "| `fmin`         | 50      | 20      |\n",
    "| `fmax`         | 14000   | 16000   |\n",
    "\n",
    "- **손실 함수 변경**\n",
    "    - **변경 전**: `BCEWithLogitsLoss`\n",
    "    - **변경 후**: `FocalLossBCE`\n",
    "\n",
    "- **후처리 가중치 변경**\n",
    "    - **변경 전**: 가장자리 세그먼트 가중 평균 = 0.8 / 0.2\n",
    "    - **변경 후**: 0.9 / 0.1로 조정\n",
    "\n",
    "---\n",
    "\n",
    "### **4. 모델 아키텍처 수정 (PB 0.825 → 0.835 | PV 0.841 → 0.847)**\n",
    "\n",
    "- **백본과 헤드 분리**\n",
    "    - **변경 전**: 백본 내부에 포함된 classifier 레이어 사용\n",
    "    - **변경 후**: `features_only=True` 설정으로 백본에서 feature map만 추출\n",
    "\n",
    "- **커스텀 컨볼루션 헤드 적용**\n",
    "    - `1×1 Conv`를 사용하여 채널 간 상호작용 강화\n",
    "    - 분류기 구성: `AdaptiveAvgPool → Flatten → Linear`\n",
    "\n",
    "- **분석**\n",
    "    - 백본과 헤드를 분리함으로써 사전학습된 feature를 더욱 효과적으로 활용\n",
    "    - Conv head가 공간적 패턴을 보다 잘 포착하여 성능 향상에 기여\n",
    "\n",
    "---\n",
    "\n",
    "### **[5. 공개 모델 앙상블 (PB 0.835 → 0.878 | PV 0.847 → 0.893)](https://www.kaggle.com/code/johnyim1570/bird25-weightedblend-nfnet-seresnext-0-878)**\n",
    "\n",
    "- **참고한 공개 노트북**\n",
    "    - 🔗 **블렌딩 로직**: [WeightedBlend | NFNet + ConvNeXtV2 | LB 0.860](https://www.kaggle.com/code/hideyukizushi/bird25-weightedblend-nfnet-convnextv2-lb-860) – by [yukiZ](https://www.kaggle.com/hideyukizushi)\n",
    "    - 🧪 **NFNet 모델 (PB 0.857)**: [Single SED Model Inference](https://www.kaggle.com/code/i2nfinit3y/bird2025-single-sed-model-inference-lb-0-857) – by [I2nfinit3y](https://www.kaggle.com/i2nfinit3y)\n",
    "    - 📘 **SE-ResNeXt 모델 (PB 0.850)**: [후처리 + 파워 조정 기반 앙상블](https://www.kaggle.com/code/myso1987/post-processing-with-power-adjustment-for-low-rank) – by [MYSO](https://www.kaggle.com/myso1987)\n",
    "\n",
    "- **모델 교체**\n",
    "    - WeightedBlend 공개 노트북에 포함된 기존 모델들을 위의 성능 좋은 두 모델로 교체\n",
    "    - 추론 단계에서 앙상블 적용\n",
    "\n",
    "- **블렌딩 비율**\n",
    "    - NFNet: 25%\n",
    "    - SE-ResNeXt: 75%\n",
    "\n",
    "---\n",
    "\n",
    "### **6. NFNet 후처리 개선 (PB 0.878 → 0.881 | PV 0.893 → 0.891)**\n",
    "\n",
    "- **파워 조정 하이퍼파라미터 튜닝**\n",
    "    - **변경 전**: `top_k=30` 이하의 tail column에 `exponent=2` 고정 적용\n",
    "    - **변경 후**: tail column을 3개 구간으로 나눠 다른 지수 적용\n",
    "        - 순위 31–100: `exponent=2`\n",
    "        - 순위 101–150: `exponent=3`\n",
    "        - 순위 151 이상: `exponent=4`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94a656",
   "metadata": {},
   "source": [
    "## 🧠 **결론 및 회고**\n",
    "\n",
    "2022년부터 2024년까지의 BirdCLEF 리더보드를 분석한 결과,\n",
    "대부분의 참가자들이 **Public 점수 대비 Private 점수가 하락하는 경향**을 보였으며,\n",
    "특히 Silver 메달 이외의 구간에서 이러한 현상이 두드러진 모습을 보였다.\n",
    "그리고 Kaggle Discussions 내에서는 **Public 테스트셋에 과적합** 되는 문제에 대한 우려가 지속적으로 제기되었다.\n",
    "\n",
    "WeightedBlend 앙상블(PB 0.878)은 다양한 가중치 비율(예: 0.5:0.5 → 0.75:0.25)을 실험하며 조정되었고,\n",
    "후처리 기법 적용을 통해 PB 0.881까지 개선되는 결과를 보였다.\n",
    "다만 해당 성능 향상이 **Public 테스트셋에 과적합된 결과일 가능성**이 높다고 판단되었다.\n",
    "\n",
    "이에 따라 **최종 제출 전략은** 다음과 같았다:\n",
    "1. 독자적으로 학습한 최고 성능의 모델 (**PB 0.835**)\n",
    "2. Public 점수가 가장 높은 앙상블 모델 (**PB 0.881**)\n",
    "\n",
    "하지만 Private 리더보드가 공개된 후, **기존의 예측을 완전히 뒤엎는 결과**가 확인되었다.\n",
    "**모든 제출 결과가 Private 점수에서 오히려 상승하는 경향**을 보였으며,\n",
    "이러한 추세는 여러 팀에게서도 동일하게 나타났다.\n",
    "특히 초기 앙상블 모델(PB 0.878)은 **Private 0.893**이라는 점수를 기록하며, 최종 제출한 앙상블 모델(PB 0.881) 보다 **오히려 더 높은 Bronze 메달 범위에 포함되는 성과**를 보여주었다.\n",
    "\n",
    "### ❗ **요약**\n",
    "- 과거 리더보드 경향에 기반한 가정은 **이번 대회에 적용되지 않는 양상**을 보였다\n",
    "- **보수적인 제출 전략**은 **최종 순위 하락**으로 이어지는 결과를 초래했다\n",
    "- **Public 순위: 162위 → Private 순위: 507위**로 마감되었다\n",
    "\n",
    "---\n",
    "\n",
    "## 😓 **기술적 한계 및 아쉬움**\n",
    "\n",
    "나는 이번 대회에서 다음 두가지 영역을 핵심이라고 생각했다:\n",
    "\n",
    "1. `train_audio`의 Weak Labeled 데이터를 **어떻게 전처리하고 학습에 활용할 것인지**  \n",
    "2. `train_soundscapes`에서 **신뢰 가능한 pseudo-label을 생성하여 semi-supervised 학습에 사용할 수 있는지**\n",
    "\n",
    "1번 문제에 대해서는 **대부분의 조류 소리가 고주파수 대역(2kHz 이상)에서 발생한다는 통계적 특성**에 착안하여 다음과 같은 값으로 설정했다:\n",
    "\n",
    "> 2kHz 이상 대역에서 -27.5dB 이상의 신호가 포함된 5초 세그먼트를 선별\n",
    "\n",
    "이 방식은 일정 수준의 성능 향상을 보여주었지만, 곧 성능 향상 곡선이 완만해지는 한계를 드러냈다.  \n",
    "결국 해당 기준은 pseudo-label 생성 기준으로 활용되기엔 불안정하다고 판단되어,  \n",
    "**`train_soundscapes`데이터는 전혀 사용하지 않았다.**\n",
    "\n",
    "대회 중반에는 **MIL(Multiple Instance Learning)** 개념을 새롭게 확인하게 되었으며:\n",
    "\n",
    "> 약한 라벨이 주어진 상황에서도 모델이 실제 클래스가 등장하는 시점만을 집중적으로 학습할 수 있도록 하는 방법으로,\n",
    "> 앞선 두 과제를 통합적으로 해결할 가능성을 내포하고 있음\n",
    "\n",
    "그러나 대회 후반의 시간 제약과 코드 제출 과정의 오류로 인해\n",
    "**MIL 기반 추론 코드는 최종적으로 제출되지 못하는 결과를 보였다.**\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 **기술적 성장 및 인사이트**\n",
    "\n",
    "비록 제약이 존재했지만, 이번 BirdCLEF 대회는 다음과 같은 경험과 기술적 성장을 이끌어내는 계기가 되었다:\n",
    "\n",
    "- 전처리 방식, 모델 구조, 후처리 기법 등을 독자적으로 설계하고 검증하여 **실질적인 성능 향상을 유도한 경험**을 확보함  \n",
    "- 대회 종료 후 상위 솔루션 분석을 통해 **Teacher–Student 기반 지식 증류(knowledge distillation)** 개념을 처음으로 접하고 학습함\n",
    "- **다중 라벨 오디오 분류 문제에서 데이터 분포 분석, 과적합 탐지, 제출 전략 설계 등** 실무적인 통찰을 얻게 되는 경험으로 이어졌음"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
